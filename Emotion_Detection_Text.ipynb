{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "36f38e2a-9998-4c73-bfc3-21b74d64a5ee",
      "metadata": {
        "id": "36f38e2a-9998-4c73-bfc3-21b74d64a5ee"
      },
      "source": [
        "# Text-Based emotion detection "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24fbeedf",
      "metadata": {
        "id": "24fbeedf"
      },
      "outputs": [],
      "source": [
        "!pip install neattext\n",
        "!pip install text_hammer \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Pj5ST139uyhk"
      },
      "id": "Pj5ST139uyhk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0814628-3d83-4fd6-a511-2eccf79f9f1e",
      "metadata": {
        "id": "f0814628-3d83-4fd6-a511-2eccf79f9f1e"
      },
      "outputs": [],
      "source": [
        "# Load EDA Pkgs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import neattext.functions as nfx\n",
        "# Load ML Pkgs\n",
        " \n",
        "# Estimators\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Transformers => vectorization \n",
        "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer \n",
        " \n",
        "# metrics \n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "\n",
        "# to split the dataset to training and testing dataset \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import text_hammer as th\n",
        "\n",
        "from tqdm._tqdm_notebook import tqdm_notebook\n",
        "tqdm_notebook.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b209e004-ab77-4407-8689-b4318944d47f",
      "metadata": {
        "id": "b209e004-ab77-4407-8689-b4318944d47f"
      },
      "outputs": [],
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/emotion_dataset_raw.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fea2d4c0-3bdd-405e-ab69-507ceaac36cb",
      "metadata": {
        "id": "fea2d4c0-3bdd-405e-ab69-507ceaac36cb"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c4950ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c4950ed",
        "outputId": "f42f08b6-16a2-4b45-a4e5-7dca3af12871"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34792, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "430565a3-cf3b-4c6f-afa5-bafd084f5676",
      "metadata": {
        "id": "430565a3-cf3b-4c6f-afa5-bafd084f5676"
      },
      "outputs": [],
      "source": [
        "# Value Counts\n",
        "df['Emotion'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "540873b3",
      "metadata": {
        "id": "540873b3"
      },
      "outputs": [],
      "source": [
        "df.drop(df[df.Emotion == \"shame\"].index, inplace=True)\n",
        "df.drop(df[df.Emotion == \"disgust\"].index, inplace=True)\n",
        "df.Emotion=df.Emotion.replace({\"joy\":0, 'sadness':1, \"fear\":2, \"anger\":3, \"surprise\":4, \"neutral\":5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d23dcb40",
      "metadata": {
        "id": "d23dcb40"
      },
      "outputs": [],
      "source": [
        "df['Emotion'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b99931e",
      "metadata": {
        "id": "4b99931e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "df['Emotion'] = to_categorical(df['Emotion'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "531d3449-a959-4a19-bff0-3ffed551e619",
      "metadata": {
        "id": "531d3449-a959-4a19-bff0-3ffed551e619"
      },
      "outputs": [],
      "source": [
        "# Plot\n",
        "sns.countplot(x='Emotion',data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5605d018",
      "metadata": {
        "id": "5605d018"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12f97b32",
      "metadata": {
        "id": "12f97b32"
      },
      "source": [
        "## Sentiment Analysis "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd302866",
      "metadata": {
        "id": "dd302866"
      },
      "outputs": [],
      "source": [
        "! pip install textblob\n",
        "from textblob import TextBlob\n",
        "def get_sentiment(text):\n",
        "    blob = TextBlob(text)\n",
        "    sentiement = blob.sentiment.polarity\n",
        "    result = \"\"\n",
        "    if sentiement > 0 :\n",
        "        result = \"Positive\"\n",
        "    elif sentiement < 0 :\n",
        "        result = \"Negative\"\n",
        "    else :\n",
        "        result = \"Neutral\"\n",
        "    return result "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23f68f8d",
      "metadata": {
        "id": "23f68f8d"
      },
      "outputs": [],
      "source": [
        "get_sentiment(\"i love programming\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1cc64c0",
      "metadata": {
        "id": "a1cc64c0"
      },
      "outputs": [],
      "source": [
        "df2=df \n",
        "df2['Sentiment'] = df2[\"Text\"].apply(get_sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b17463be",
      "metadata": {
        "id": "b17463be"
      },
      "outputs": [],
      "source": [
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88e99e9f",
      "metadata": {
        "id": "88e99e9f"
      },
      "outputs": [],
      "source": [
        "# let's compare between emotions and sentiments \n",
        "df2.groupby(['Emotion','Sentiment']).size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "853cf823",
      "metadata": {
        "id": "853cf823"
      },
      "outputs": [],
      "source": [
        "df2.groupby(['Emotion','Sentiment']).size().plot(kind=\"bar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d362faed",
      "metadata": {
        "id": "d362faed"
      },
      "outputs": [],
      "source": [
        "# another way for plotting data \n",
        "sns.catplot(x=\"Emotion\",hue=\"Sentiment\",data=df2,kind=\"count\",aspect=1.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6867ebe",
      "metadata": {
        "id": "e6867ebe"
      },
      "source": [
        "## clean the Text "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40f991d0-952f-40c1-bf00-f3476ce0436d",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "scrolled": true,
        "tags": [],
        "id": "40f991d0-952f-40c1-bf00-f3476ce0436d"
      },
      "outputs": [],
      "source": [
        "# Data Cleaning\n",
        "dir(nfx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1f87847-a91c-4bd6-a307-d746eb5aa9a0",
      "metadata": {
        "id": "b1f87847-a91c-4bd6-a307-d746eb5aa9a0"
      },
      "outputs": [],
      "source": [
        "# User handles\n",
        "df2['Clean_Text'] = df2['Text'].apply(nfx.remove_userhandles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03886bc3-1ac4-4f1b-842b-e5d2d770ff81",
      "metadata": {
        "id": "03886bc3-1ac4-4f1b-842b-e5d2d770ff81"
      },
      "outputs": [],
      "source": [
        "# Stopwords\n",
        "df2['Clean_Text'] = df2['Clean_Text'].apply(nfx.remove_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b894bf47",
      "metadata": {
        "id": "b894bf47"
      },
      "outputs": [],
      "source": [
        "\n",
        "df2['Clean_Text'] = df2['Clean_Text'].apply(nfx.remove_hashtags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a638e96d",
      "metadata": {
        "id": "a638e96d"
      },
      "outputs": [],
      "source": [
        "\n",
        "df2['Clean_Text'] = df2['Clean_Text'].apply(nfx.remove_punctuations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b7b71f0",
      "metadata": {
        "id": "3b7b71f0"
      },
      "outputs": [],
      "source": [
        "df2['Clean_Text'].str.replace(\")\",\"\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "714ee2f7",
      "metadata": {
        "id": "714ee2f7"
      },
      "outputs": [],
      "source": [
        "df2['Clean_Text'].str.replace(\"(\",\"\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68b2520f",
      "metadata": {
        "id": "68b2520f"
      },
      "outputs": [],
      "source": [
        "df2['Clean_Text'].str.replace(\":\",\"\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02756e8c",
      "metadata": {
        "id": "02756e8c"
      },
      "outputs": [],
      "source": [
        "df2['Clean_Text'].str.replace(\"'\",\"\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a0fcc0c-4adf-4f0b-b226-164659ad70ba",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "0a0fcc0c-4adf-4f0b-b226-164659ad70ba"
      },
      "outputs": [],
      "source": [
        "df2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c1858c4",
      "metadata": {
        "id": "4c1858c4"
      },
      "source": [
        "## Keyword extraction "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee395930",
      "metadata": {
        "id": "ee395930"
      },
      "source": [
        "- exract the most common word in each class "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c44dc3f7",
      "metadata": {
        "id": "c44dc3f7"
      },
      "outputs": [],
      "source": [
        "from collections import Counter "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edaca842",
      "metadata": {
        "id": "edaca842"
      },
      "outputs": [],
      "source": [
        "def extraxt_keywords(text,num=50):\n",
        "    tokens = [tok for tok in text.split()]\n",
        "    most_common_tokens = Counter(tokens).most_common(num)\n",
        "    return dict(most_common_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98b25ade",
      "metadata": {
        "id": "98b25ade"
      },
      "source": [
        "-let's check it , in a simple example on calculating the most common word in \"joy\" class \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84652328",
      "metadata": {
        "id": "84652328"
      },
      "outputs": [],
      "source": [
        "emotion_list = df2['Emotion'].unique().tolist()\n",
        "print(emotion_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b56588c",
      "metadata": {
        "id": "3b56588c"
      },
      "outputs": [],
      "source": [
        "joy_list = df2[df2['Emotion']==0]['Clean_Text'].tolist()\n",
        "for i in joy_list:\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9351112",
      "metadata": {
        "id": "e9351112"
      },
      "outputs": [],
      "source": [
        "# make the list as a string so we can calculate the most common word \n",
        "joy_docx = ' '.join(joy_list)\n",
        "print(joy_docx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cf3c92d",
      "metadata": {
        "id": "6cf3c92d"
      },
      "outputs": [],
      "source": [
        "# extract the most common words in joy_docx \n",
        "key_dict = extraxt_keywords(joy_docx)\n",
        "key_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0e7cac5",
      "metadata": {
        "id": "e0e7cac5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pylab as plt\n",
        "# plot the most common word \n",
        "def plot_most_common_words(mydict,emotion_name):\n",
        "    df_01 = pd.DataFrame(mydict.items(),columns=['taken','count'])\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.title(\"Plot of {}\".format(emotion_name))\n",
        "    sns.barplot(x='taken',y='count',data=df_01)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee9ff3ff",
      "metadata": {
        "id": "ee9ff3ff"
      },
      "outputs": [],
      "source": [
        "plot_most_common_words(key_dict,\"Joy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ec52a34",
      "metadata": {
        "id": "3ec52a34"
      },
      "outputs": [],
      "source": [
        "sadness_list = df2[df2['Emotion']==1]['Clean_Text'].tolist() # get the list of emotion_category \n",
        "sadness_docx = ' '.join(sadness_list) # make it as one string \n",
        "key_dict_sadness = extraxt_keywords(sadness_docx) # count each word \n",
        "print(key_dict_sadness)\n",
        "plot_most_common_words(key_dict_sadness,\"sadness\") # plot the results "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f18d4073",
      "metadata": {
        "id": "f18d4073"
      },
      "outputs": [],
      "source": [
        "# word cloud\n",
        "#!pip install wordcloud\n",
        "from wordcloud import WordCloud "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29aaaa92",
      "metadata": {
        "id": "29aaaa92"
      },
      "outputs": [],
      "source": [
        "def plot_wordcloud(docx):\n",
        "    myWordCloud = WordCloud().generate(docx)\n",
        "    plt.figure(figsize=(15,10))\n",
        "    plt.imshow(myWordCloud,interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "042046a0",
      "metadata": {
        "id": "042046a0"
      },
      "outputs": [],
      "source": [
        "plot_wordcloud(joy_docx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "495f18e5",
      "metadata": {
        "id": "495f18e5"
      },
      "outputs": [],
      "source": [
        "plot_wordcloud(sadness_docx)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1f2499d",
      "metadata": {
        "id": "f1f2499d"
      },
      "source": [
        "## Machine learning Text classification "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37b4616d",
      "metadata": {
        "id": "37b4616d"
      },
      "source": [
        "+ SVM \n",
        "+ naive bayes \n",
        "+ logestic regression \n",
        "+ KNN \n",
        "+ Descision tree \n",
        "\n",
        "+ compare with sparkNLP / NLU john snows lab "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a552ab08",
      "metadata": {
        "id": "a552ab08"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83b46bed",
      "metadata": {
        "id": "83b46bed"
      },
      "outputs": [],
      "source": [
        "# Features & Labels\n",
        "Xfeatures = df2['Clean_Text']\n",
        "ylabels = df2['Emotion']\n",
        "print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
        "print(Xfeatures.head())\n",
        "print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
        "print(ylabels.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d2d5f6b",
      "metadata": {
        "id": "6d2d5f6b"
      },
      "source": [
        "machine learning model cann't understand the text so we have to transfer the text to numbers , this process called vectorization "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "769e334a",
      "metadata": {
        "id": "769e334a"
      },
      "outputs": [],
      "source": [
        "#vectorization \n",
        "cv = CountVectorizer()\n",
        "x=cv.fit_transform(Xfeatures)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03cbc385",
      "metadata": {
        "scrolled": true,
        "id": "03cbc385"
      },
      "outputs": [],
      "source": [
        "# get features by name \n",
        "cv.get_feature_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f320670f",
      "metadata": {
        "id": "f320670f"
      },
      "outputs": [],
      "source": [
        "# to Dense Numpy array \n",
        "#x.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27d7f976-c28f-449e-ae1a-53a42bbda4e8",
      "metadata": {
        "id": "27d7f976-c28f-449e-ae1a-53a42bbda4e8"
      },
      "outputs": [],
      "source": [
        "#  Split the Dataset\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,ylabels,test_size=0.3,random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6d783b0",
      "metadata": {
        "id": "f6d783b0"
      },
      "source": [
        "## Build our model \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ef4be4a",
      "metadata": {
        "id": "7ef4be4a"
      },
      "outputs": [],
      "source": [
        "# y_train = to_categorical(df.Sentiment.values)\n",
        "# y_test = to_categorical(df_test.Sentiment.values)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "039d3508",
      "metadata": {
        "id": "039d3508"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7538a9a3",
      "metadata": {
        "id": "7538a9a3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn import datasets\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import cycle\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "620ed8a0",
      "metadata": {
        "id": "620ed8a0"
      },
      "outputs": [],
      "source": [
        "np.random.seed(610)\n",
        "\n",
        "linearr = svm.SVC(kernel='linear', decision_function_shape='ovr').fit(x_train, y_train)\n",
        "predictionslinn = linearr.predict(x_test)\n",
        "print(\"linear: \",accuracy_score(y_test,predictionslinn))\n",
        "\n",
        "rbff = svm.SVC(kernel='rbf', decision_function_shape='ovr').fit(x_train, y_train)\n",
        "predictionslinnn = rbff.predict(x_test)\n",
        "print(\"rbf: \",accuracy_score(y_test,predictionslinnn))\n",
        "\n",
        "\n",
        "polyy = svm.SVC(kernel='poly', decision_function_shape='ovr').fit(x_train, y_train)\n",
        "predictionslinp = polyy.predict(x_test)\n",
        "print(\"poly: \",accuracy_score(y_test,predictionslinp))\n",
        "\n",
        "sigg = svm.SVC(kernel='sigmoid', decision_function_shape='ovr').fit(x_train, y_train)\n",
        "predictionslins = sigg.predict(x_test)\n",
        "print(\"sig: \",accuracy_score(y_test,predictionslins))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ff43998",
      "metadata": {
        "id": "6ff43998"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d28284fb",
      "metadata": {
        "id": "d28284fb"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier( criterion = 'entropy', random_state = 42)\n",
        "classifier.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12dfa5cd",
      "metadata": {
        "id": "12dfa5cd"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29ebe607",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29ebe607",
        "outputId": "5898c142-ebab-45e8-841a-e3289997331f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc:  0.789286771234093\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"acc: \",accuracy_score(y_test,y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13d448e5",
      "metadata": {
        "id": "13d448e5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "233733a9",
      "metadata": {
        "id": "233733a9"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f815f1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f815f1e",
        "outputId": "c79e8984-8021-48c7-c891-028845b7dbc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "nv_model = MultinomialNB()\n",
        "nv_model.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97fe8733",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97fe8733",
        "outputId": "f888e106-fe52-4272-f03c-729fe898017c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7911610930255499"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "# check the accuracy of the model \n",
        "# method 1 : \n",
        "nv_model.score(x_test,y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f1267c2",
      "metadata": {
        "id": "9f1267c2"
      },
      "source": [
        "## logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef91657c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef91657c",
        "outputId": "d089c03f-46c4-49b8-c32e-be5ca5063318"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(x_train,y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a3a9c11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a3a9c11",
        "outputId": "415b60df-fe76-4739-cf63-0a2ac9feb488"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8002367564368156"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "# check the accuracy of the linear regression model \n",
        "lr_model.score(x_test , y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d51d90a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d51d90a1",
        "outputId": "e1d57a12-ff0f-4f89-a797-26eef4920ba3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:1.0, Prediction score :0.8645504024219197\n"
          ]
        }
      ],
      "source": [
        "def predict_emotion(text,model):\n",
        "    # vectorizing the text that will be an input to the model\n",
        "    vectorized_text = cv.transform(text).toarray() \n",
        "    prediction = model.predict(vectorized_text)\n",
        "    prediction_probability = model.predict_proba(vectorized_text)\n",
        "    prediction_percentage_for_all = dict(zip(model.classes_ , prediction_probability[0])) \n",
        "    print(\"Prediction:{}, Prediction score :{}\".format(prediction[0],np.max(prediction_probability)))\n",
        "    #return prediction_percentage_for_all\n",
        "                                         \n",
        "sample_test = [\"i love artificial intelligence so much \"] # text  to test the model with \n",
        "predict_emotion(sample_test,nv_model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fba9def",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fba9def",
        "outputId": "a39535f2-8762-4649-ca41-7fdbde0d301a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:1.0, Prediction score :0.6862010432607868\n"
          ]
        }
      ],
      "source": [
        "# a single prediction using linear regression model \n",
        "sample_test2 = [\"i love DEBI \"] # text  to test the model with \n",
        "predict_emotion(sample_test2,lr_model) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc28cef0",
      "metadata": {
        "id": "dc28cef0"
      },
      "source": [
        "### Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b463337",
      "metadata": {
        "id": "4b463337"
      },
      "outputs": [],
      "source": [
        "import joblib "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e704d3b",
      "metadata": {
        "id": "4e704d3b"
      },
      "outputs": [],
      "source": [
        "model_file=open(\"Text_based_emotion_classifier_nv_model_26_april_2022.pkl\",\"wb\")\n",
        "joblib.dump(lr_model,model_file)\n",
        "model_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df13e662",
      "metadata": {
        "id": "df13e662"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Emotion_Detection_Text.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}